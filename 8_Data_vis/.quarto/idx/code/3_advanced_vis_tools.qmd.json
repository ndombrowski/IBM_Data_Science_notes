{"title":"Advanced visualization tools","markdown":{"headingText":"Advanced visualization tools","containsRefs":false,"markdown":"\n## Notebook setup\n\n```{python}\n#load libs\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nfrom PIL import Image\nimport json\n\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nimport matplotlib.patches as mpatches # needed for waffle Charts\n\nimport folium\n```\n\n\n```{python}\n#load data\ndf_can = pd.read_excel(\"../data/Canada.xlsx\", sheet_name='Canada by Citizenship',skiprows=range(20), skipfooter=2)\n\n#check data\nprint(df_can.head(3))\n```\n```{python}\n# clean up the dataset to remove unnecessary columns (eg. REG) \ndf_can.drop(['AREA','REG','DEV','Type','Coverage'], axis = 1, inplace = True)\n\n# let's rename the columns so that they make sense\ndf_can.rename (columns = {'OdName':'Country', 'AreaName':'Continent','RegName':'Region'}, inplace = True)\n\n# for sake of consistency, let's also make all column labels of type string\ndf_can.columns = list(map(str, df_can.columns))\n\n# set the country name as index - useful for quickly looking up countries using .loc method\ndf_can.set_index('Country', inplace = True)\n\n# years that we will be using in this lesson - useful for plotting later on\nyears = list(map(str, range(1980, 2014)))\n\n# add total column\ndf_can['Total'] =  df_can[years].sum (axis = 1)\n\n#control dimensions\nprint ('data dimensions:', df_can.shape)\n```\n\n\n\n## Waffle charts\n\nA waffle chart is a great way to visualize data in relation to a whole or to highlight progress against a given threshold.\n\nLet's revisit the previous case study about Denmark, Norway, and Sweden.\n\n```{python}\ndf_dsn = df_can.loc[['Denmark', 'Norway', 'Sweden']]\ndf_dsn.head()\n```\nUnfortunately, unlike R, waffle charts are not built into any of the Python visualization libraries. Therefore, we will learn how to create them from scratch.\n\nStep 1. The first step into creating a waffle chart is determining the proportion of each category with respect to the total.\n\n```{python}\n#compute the proportion of each category with respect to the total\ntotal_values = df_dsn['Total'].sum()\ncategory_proportions = df_dsn['Total'] / total_values\n\n# print out proportions\npd.DataFrame({\"Category Proportion\": category_proportions})\n```\n\nStep 2. The second step is defining the overall size of the waffle chart.\n\n```{python}\nwidth=40\nheight=10\n\ntotal_num_tiles = width * height\n\nprint(f'Total number of tiles is {total_num_tiles}.')\n```\n\nStep 3. The third step is using the proportion of each category to determe it respective number of tiles\n\n```{python}\ntiles_per_category = (category_proportions * total_num_tiles).round().astype(int)\n\n# print out number of tiles per category\npd.DataFrame({\"Number of tiles\": tiles_per_category})\n```\n\nBased on the calculated proportions, Denmark will occupy 129 tiles of the waffle chart, Norway will occupy 77 tiles, and Sweden will occupy 194 tiles.\n\nStep 4. The fourth step is creating a matrix that resembles the waffle chart and populating it.\n\n```{python}\n# initialize the waffle chart as an empty matrix\nwaffle_chart = np.zeros((height, width), dtype = np.uint)\n\n# define indices to loop through waffle chart\ncategory_index = 0\ntile_index = 0\n```\n\n```{python}\n# populate the waffle chart\nfor col in range(width):\n    for row in range(height):\n        tile_index += 1\n        # if the number of tiles populated for the current category is equal to its corresponding allocated tiles...\n        if tile_index > sum(tiles_per_category[0:category_index]):\n            # ...proceed to the next category\n            category_index += 1       \n        # set the class value to an integer, which increases with class\n        waffle_chart[row, col] = category_index\nprint ('Waffle chart populated!')\n```\n\n```{python}\n#view chart\nwaffle_chart\n```\nAs expected, the matrix consists of three categories and the total number of each category's instances matches the total number of tiles allocated to each category.\n\nStep 5. Map the waffle chart matrix into a visual.\n\n```{python}\n# instantiate a new figure object\nfig = plt.figure()\n\n# use matshow to display the waffle chart\ncolormap = plt.cm.coolwarm\nplt.matshow(waffle_chart, cmap=colormap)\nplt.colorbar()\n\nplt.show()\nplt.close()\n```\nPrettify\n\n```{python}\n# instantiate a new figure object\nfig = plt.figure()\n\n# use matshow to display the waffle chart\ncolormap = plt.cm.coolwarm\nplt.matshow(waffle_chart, cmap=colormap)\nplt.colorbar()\n\n# get the axis\nax = plt.gca()\n\n# set minor ticks\nax.set_xticks(np.arange(-.5, (width), 1), minor=True)\nax.set_yticks(np.arange(-.5, (height), 1), minor=True)\n    \n# add gridlines based on minor ticks\nax.grid(which='minor', color='w', linestyle='-', linewidth=2)\n\nplt.xticks([])\nplt.yticks([])\nplt.show()\nplt.close()\n```\nStep 7. Create a legend and add it to chart.\n\n```{python}\n# instantiate a new figure object\nfig = plt.figure()\n\n# use matshow to display the waffle chart\ncolormap = plt.cm.coolwarm\nplt.matshow(waffle_chart, cmap=colormap)\nplt.colorbar()\n\n# get the axis\nax = plt.gca()\n\n# set minor ticks\nax.set_xticks(np.arange(-.5, (width), 1), minor=True)\nax.set_yticks(np.arange(-.5, (height), 1), minor=True)\n    \n# add gridlines based on minor ticks\nax.grid(which='minor', color='w', linestyle='-', linewidth=2)\n\nplt.xticks([])\nplt.yticks([])\n\n# compute cumulative sum of individual categories to match color schemes between chart and legend\nvalues_cumsum = np.cumsum(df_dsn['Total'])\ntotal_values = values_cumsum[len(values_cumsum) - 1]\n\n# create legend\nlegend_handles = []\nfor i, category in enumerate(df_dsn.index.values):\n    label_str = category + ' (' + str(df_dsn['Total'][i]) + ')'\n    color_val = colormap(float(values_cumsum[i])/total_values)\n    legend_handles.append(mpatches.Patch(color=color_val, label=label_str))\n\n# add legend to chart\nplt.legend(handles=legend_handles,\n           loc='lower center', \n           ncol=len(df_dsn.index.values),\n           bbox_to_anchor=(0., -0.2, 0.95, .1)\n          )\nplt.show()\n\nplt.close()\n```\nNow it would very inefficient to repeat these seven steps every time we wish to create a `waffle` chart. So let's combine all seven steps into one function called *create_waffle_chart*. This function would take the following parameters as input:\n\n1.  **categories**: Unique categories or classes in dataframe.\n2.  **values**: Values corresponding to categories or classes.\n3.  **height**: Defined height of waffle chart.\n4.  **width**: Defined width of waffle chart.\n5.  **colormap**: Colormap class\n6.  **value_sign**: In order to make our function more generalizable, we will add this parameter to address signs that could be associated with a value such as %, $, and so on. **value_sign** has a default value of empty string.\n\n```{python}\ndef create_waffle_chart(categories, values, height, width, colormap, value_sign=''):\n\n    # compute the proportion of each category with respect to the total\n    total_values = sum(values)\n    category_proportions = [(float(value) / total_values) for value in values]\n\n    # compute the total number of tiles\n    total_num_tiles = width * height # total number of tiles\n    print ('Total number of tiles is', total_num_tiles)\n    \n    # compute the number of tiles for each catagory\n    tiles_per_category = [round(proportion * total_num_tiles) for proportion in category_proportions]\n\n    # print out number of tiles per category\n    for i, tiles in enumerate(tiles_per_category):\n        print (df_dsn.index.values[i] + ': ' + str(tiles))\n    \n    # initialize the waffle chart as an empty matrix\n    waffle_chart = np.zeros((height, width))\n\n    # define indices to loop through waffle chart\n    category_index = 0\n    tile_index = 0\n\n    # populate the waffle chart\n    for col in range(width):\n        for row in range(height):\n            tile_index += 1\n\n            # if the number of tiles populated for the current category \n            # is equal to its corresponding allocated tiles...\n            if tile_index > sum(tiles_per_category[0:category_index]):\n                # ...proceed to the next category\n                category_index += 1       \n            \n            # set the class value to an integer, which increases with class\n            waffle_chart[row, col] = category_index\n    \n    # instantiate a new figure object\n    fig = plt.figure()\n\n    # use matshow to display the waffle chart\n    colormap = plt.cm.coolwarm\n    plt.matshow(waffle_chart, cmap=colormap)\n    plt.colorbar()\n\n    # get the axis\n    ax = plt.gca()\n\n    # set minor ticks\n    ax.set_xticks(np.arange(-.5, (width), 1), minor=True)\n    ax.set_yticks(np.arange(-.5, (height), 1), minor=True)\n    \n    # add dridlines based on minor ticks\n    ax.grid(which='minor', color='w', linestyle='-', linewidth=2)\n\n    plt.xticks([])\n    plt.yticks([])\n\n    # compute cumulative sum of individual categories to match color schemes between chart and legend\n    values_cumsum = np.cumsum(values)\n    total_values = values_cumsum[len(values_cumsum) - 1]\n\n    # create legend\n    legend_handles = []\n    for i, category in enumerate(categories):\n        if value_sign == '%':\n            label_str = category + ' (' + str(values[i]) + value_sign + ')'\n        else:\n            label_str = category + ' (' + value_sign + str(values[i]) + ')'\n            \n        color_val = colormap(float(values_cumsum[i])/total_values)\n        legend_handles.append(mpatches.Patch(color=color_val, label=label_str))\n\n    # add legend to chart\n    plt.legend(\n        handles=legend_handles,\n        loc='lower center', \n        ncol=len(categories),\n        bbox_to_anchor=(0., -0.2, 0.95, .1)\n    )\n    plt.show()\n    plt.close()\n```\nNow to create a waffle chart, all we have to do is call the function create_waffle_chart. Let's define the input parameters:\n\n```{python}\nwidth = 40 # width of chart\nheight = 10 # height of chart\n\ncategories = df_dsn.index.values # categories\nvalues = df_dsn['Total'] # correponding values of categories\n\ncolormap = plt.cm.coolwarm # color map class\n```\n\nAnd now let's call our function to create a waffle chart.\n\n```{python}\ncreate_waffle_chart(categories, values, height, width, colormap)\nplt.close()\n```\n\nThere seems to be a new Python package for generating `waffle charts` called [PyWaffle](https://github.com/ligyxy/PyWaffle), but it looks like the repository is still being built. But feel free to check it out and play with it.\n\n\n\n## Word clouds\n\nA word cloud is simply a depiction of the importance of different words in the body of text. A word cloud works in a simple way; the more a specific word appears in a source of textual data the bigger and bolder it appears in the world cloud. \n\nLuckily, a Python package already exists in Python for generating `word` clouds. The package, called `word_cloud` was developed by **Andreas Mueller**. You can learn more about the package by following this [link](https://github.com/amueller/word_cloud/).\n\n\n\n## Seaborn and regression plots\n\nSeaborn is another data visualization library, based on Matplotlib. It was built primarily to provide a high-level interface for drawing attractive statistical graphics, such as regression plots, box plots, ... in a more efficient way.\n\nIn lab *Pie Charts, Box Plots, Scatter Plots, and Bubble Plots*, we learned how to create a scatter plot and then fit a regression line. It took \\~20 lines of code to create the scatter plot along with the regression fit. In this final section, we will explore *seaborn* and see how efficient it is to create regression lines and fits using this library!\n\nCreate a new dataframe that stores that total number of landed immigrants to Canada per year from 1980 to 2013.\n\n```{python}\n#get the total poulation per year\ndf_tot = pd.DataFrame(df_can[years].sum(axis=0))\n\n#change the years to fload\ndf_tot.index = map(float, df_tot.index)\n\n#reset the index and put it back as a column in the df\ndf_tot.reset_index(inplace = True)\n\n#rename columns\ndf_tot.columns = ['year', 'total']\n\n#view df\ndf_tot.head()\n```\nWith seaborn, generating a regression plot is as simple as calling the regplot function.\n\n```{python}\nsns.regplot(x='year', y='total', data = df_tot)\nplt.show()\nplt.close()\n```\nThis is not magic; it is seaborn! You can also customize the color of the scatter plot and regression line. Let's change the color to green.\n\n```{python}\nsns.regplot(x='year', y='total', data = df_tot, color = 'green')\nplt.show()\nplt.close()\n```\n\nYou can always customize the marker shape, so instead of circular markers, let's use +.\n\n```{python}\nsns.regplot(x='year', y='total', data = df_tot, color = 'green', marker = '+')\nplt.show()\nplt.close()\n```\n\nLet's blow up the plot a little so that it is more appealing to the sight.\n\n```{python}\nplt.figure(figsize=(8, 6))\nsns.regplot(x='year', y='total', data = df_tot, color = 'green', marker = '+')\nplt.show()\nplt.close()\n```\n\nAnd let's increase the size of markers so they match the new size of the figure, and add a title and x- and y-labels.\n\n```{python}\nplt.figure(figsize=(8, 6))\n\nsns.set(font_scale=1.2)\n\nsns.regplot(x='year', y='total', data = df_tot, color = 'green', marker = '+', scatter_kws={'s':200})\nax.set(xlabel = 'Year', ylabel = 'Total Immigration')\nax.set_title('Total Immigration to Canada from 1980 to 2013')\n\nplt.show()\nplt.close()\n```\n\nAmazing! A complete scatter plot with a regression fit with 5 lines of code only. Isn't this really amazing?\n\nIf you are not a big fan of the purple background, you can easily change the style to a white plain background.\n\n\n```{python}\nplt.figure(figsize=(8, 6))\n\nsns.set(font_scale=1.2)\nsns.set_style('ticks')\n\nsns.regplot(x='year', y='total', data = df_tot, color = 'green', marker = '+', scatter_kws={'s':200})\nax.set(xlabel = 'Year', ylabel = 'Total Immigration')\nax.set_title('Total Immigration to Canada from 1980 to 2013')\n\nplt.show()\nplt.close()\n```\n\nOr to a white background with gridlines.\n\n```{python}\nplt.figure(figsize=(8, 6))\n\nsns.set(font_scale=1.2)\nsns.set_style('whitegrid')\n\nsns.regplot(x='year', y='total', data = df_tot, color = 'green', marker = '+', scatter_kws={'s':200})\nax.set(xlabel = 'Year', ylabel = 'Total Immigration')\nax.set_title('Total Immigration to Canada from 1980 to 2013')\n\nplt.show()\nplt.close()\n```\n\n\n## Folium\n\nFolium is a powerful data visualization library in Python that was built primarily to help people visualize geospatial data. What is nice about Folium is that it was developed for the sole purpose of visualizing geospatial data. While other libraries are available to visualize geospatial data, such as plotly, they might have a cap on how many API calls you can make within a defined time frame. Folium, on the other hand, is completely free.\n\n\nDatasets:\n\n1.  San Francisco Police Department Incidents for the year 2016 - [Police Department Incidents](https://data.sfgov.org/Public-Safety/Police-Department-Incidents-Previous-Year-2016-/ritf-b9ki?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkDV0101ENSkillsNetwork20297740-2021-01-01) from San Francisco public data portal. Incidents derived from San Francisco Police Department (SFPD) Crime Incident Reporting system. Updated daily, showing data for the entire year of 2016. Address and location has been anonymized by moving to mid-block or to an intersection.\n\n2.  Immigration to Canada from 1980 to 2013 - [International migration flows to and from selected countries - The 2015 revision](http://www.un.org/en/development/desa/population/migration/data/empirical2/migrationflows.shtml?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkDV0101ENSkillsNetwork20297740-2021-01-01) from United Nation's website. The dataset contains annual data on the flows of international migrants as recorded by the countries of destination. The data presents both inflows and outflows according to the place of birth, citizenship or place of previous / next residence both for foreigners and nationals. For this lesson, we will focus on the Canadian Immigration data\n\nGenerating the world map is straightforward in **Folium**. You simply create a **Folium** *Map* object, and then you display it. What is attractive about **Folium** maps is that they are interactive, so you can zoom into any region of interest despite the initial zoom level.\n\n```{python}\n#define world map\nworld_map = folium.Map()\n\n#display map\nworld_map\n```\n\nYou can customize this default definition of the world map by specifying the centre of your map, and the initial zoom level.\n\nAll locations on a map are defined by their respective Latitude and Longitude values. So you can create a map and pass in a center of Latitude and Longitude values of [0, 0].\n\nFor a defined center, you can also define the initial zoom level into that location when the map is rendered. The higher the zoom level the more the map is zoomed into the center.\n\nLet's create a map centered around Canada and play with the zoom level to see how it affects the rendered map. As The higher the zoom level the more the map is zoomed into the given center.\n\n```{python}\n#define world map\nworld_map = folium.Map(location=[56.130, -106.35], zoom_start=4)\n\n#display map\nworld_map\n```\n\n\n### Stamen Toner maps\n\nThese are high-contrast B+W (black and white) maps. They are perfect for data mashups and exploring river meanders and coastal zones.\n\nLet's create a Stamen Toner map of canada with a zoom level of 4.\n\n\n```{python}\n#define world map\nworld_map = folium.Map(location=[56.130, -106.35], zoom_start=4, tiles = 'Stamen Toner')\n\n#display map\nworld_map\n```\n\n\n### Stamen Terrain maps\n\nThese are maps that feature hill shading and natural vegetation colors. They showcase advanced labeling and linework generalization of dual-carriageway roads.\n\n```{python}\n#define world map\nworld_map = folium.Map(location=[56.130, -106.35], zoom_start=4, tiles = 'Stamen Terrain')\n\n#display map\nworld_map\n```\n\n\n\n### Maps with markers\n\nLet's download and import the data on police department incidents using pandas read_csv() method.\n\n```{python}\n#load data\ndf_incidents = pd.read_csv(\"../data/Police_Department_Incidents_-_Previous_Year__2016_.csv\")\n\n#check data\nprint(df_incidents.head(3))\n```\nSo each row consists of 13 features:\n\n1.  **IncidntNum**: Incident Number\n2.  **Category**: Category of crime or incident\n3.  **Descript**: Description of the crime or incident\n4.  **DayOfWeek**: The day of week on which the incident occurred\n5.  **Date**: The Date on which the incident occurred\n6.  **Time**: The time of day on which the incident occurred\n7.  **PdDistrict**: The police department district\n8.  **Resolution**: The resolution of the crime in terms whether the perpetrator was arrested or not\n9.  **Address**: The closest address to where the incident took place\n10. **X**: The longitude value of the crime location\n11. **Y**: The latitude value of the crime location\n12. **Location**: A tuple of the latitude and the longitude values\n13. **PdId**: The police department ID\n\nThe dataframe consists of 150,500 crimes, which took place in the year 2016. In order to reduce computational cost, let's just work with the first 100 incidents in this dataset.\n\n```{python}\nlimit = 100\ndf_incidents = df_incidents.iloc[0:limit,:]\ndf_incidents.shape\n```\n\nNow that we reduced the data a little, let's visualize where these crimes took place in the city of San Francisco. We will use the default style, and we will initialize the zoom level to 12.\n\n```{python}\n# San Francisco latitude and longitude values\nlatitude = 37.77\nlongitude = -122.42\n\n\n# create map and display it\nsanfran_map = folium.Map(location=[latitude, longitude], zoom_start=12)\n\n# display the map of San Francisco\nsanfran_map\n```\n\nNow let's superimpose the locations of the crimes onto the map. The way to do that in Folium is to create a feature group with its own features and style and then add it to the sanfran_map.\n\n```{python}\n# | error: false\n\n# instantiate a feature group for the incidents in the dataframe\nincidents = folium.map.FeatureGroup()\n\n# loop through the 100 crimes and add each to the incidents feature group\nfor lat, lng, in zip(df_incidents.Y, df_incidents.X):\n    incidents.add_child(\n        folium.features.CircleMarker(\n            [lat, lng],\n            radius=5, # define how big you want the circle markers to be\n            color='yellow',\n            fill=True,\n            fill_color='blue',\n            fill_opacity=0.6\n        )\n    )\n\n# add incidents to map\nsanfran_map.add_child(incidents)\n```\n\n\nYou can also add some pop-up text that would get displayed when you hover over a marker. Let's make each marker display the category of the crime when hovered over.\n\n```{python}\n# instantiate a feature group for the incidents in the dataframe\nincidents = folium.map.FeatureGroup()\n\n# loop through the 100 crimes and add each to the incidents feature group\nfor lat, lng, in zip(df_incidents.Y, df_incidents.X):\n    incidents.add_child(\n        folium.features.CircleMarker(\n            [lat, lng],\n            radius=5, # define how big you want the circle markers to be\n            color='yellow',\n            fill=True,\n            fill_color='blue',\n            fill_opacity=0.6\n        )\n    )\n\n# add pop-up text to each marker on the map\nlatitudes = list(df_incidents.Y)\nlongitudes = list(df_incidents.X)\nlabels = list(df_incidents.Category)\n\nfor lat, lng, label in zip(latitudes, longitudes, labels):\n    folium.Marker([lat, lng], popup=label).add_to(sanfran_map)    \n    \n# add incidents to map\nsanfran_map.add_child(incidents)\n```\n\nIf you find the map to be so congested will all these markers, there are two remedies to this problem. The simpler solution is to remove these location markers and just add the text to the circle markers themselves as follows:\n\n```{python}\n# create map and display it\nsanfran_map = folium.Map(location=[latitude, longitude], zoom_start=12)\n\n# loop through the 100 crimes and add each to the map\nfor lat, lng, label in zip(df_incidents.Y, df_incidents.X, df_incidents.Category):\n    folium.features.CircleMarker(\n        [lat, lng],\n        radius=5, # define how big you want the circle markers to be\n        color='yellow',\n        fill=True,\n        popup=label,\n        fill_color='blue',\n        fill_opacity=0.6\n    ).add_to(sanfran_map)\n\n# show map\nsanfran_map\n```\n\nThe other proper remedy is to group the markers into different clusters. Each cluster is then represented by the number of crimes in each neighborhood. These clusters can be thought of as pockets of San Francisco which you can then analyze separately.\n\nTo implement this, we start off by instantiating a MarkerCluster object and adding all the data points in the dataframe to this object.\n\n```{python}\nfrom folium import plugins\n\n# let's start again with a clean copy of the map of San Francisco\nsanfran_map = folium.Map(location = [latitude, longitude], zoom_start = 12)\n\n# instantiate a mark cluster object for the incidents in the dataframe\nincidents = plugins.MarkerCluster().add_to(sanfran_map)\n\n# loop through the dataframe and add each data point to the mark cluster\nfor lat, lng, label, in zip(df_incidents.Y, df_incidents.X, df_incidents.Category):\n    folium.Marker(\n        location=[lat, lng],\n        icon=None,\n        popup=label,\n    ).add_to(incidents)\n\n# display map\nsanfran_map\n```\n\nNotice how when you zoom out all the way, all markers are grouped into one cluster, the global cluster, of 100 markers or crimes, which is the total number of crimes in our dataframe. Once you start zooming in, the global cluster will start breaking up into smaller clusters. Zooming in all the way will result in individual markers.\n\n\n### Choropleth maps\n\nA Choropleth map is a thematic map in which areas are shaded or patterned in proportion to the measurement of the statistical variable being displayed on the map, such as population density or per-capita income. The choropleth map provides an easy way to visualize how a measurement varies across a geographic area, or it shows the level of variability within a region. \n\nNow, let's create our own Choropleth map of the world depicting immigration from various countries to Canada.\n\nDownload the Canadian Immigration dataset and read it into a pandas dataframe.\n\n\n```{python}\n#load data\ndf_can = pd.read_excel(\"../data/Canada.xlsx\", sheet_name='Canada by Citizenship',skiprows=range(20), skipfooter=2)\n\n#check data\nprint(df_can.head(3))\n```\n\n```{python}\n# clean up the dataset to remove unnecessary columns (eg. REG) \ndf_can.drop(['AREA','REG','DEV','Type','Coverage'], axis=1, inplace=True)\n\n# let's rename the columns so that they make sense\ndf_can.rename(columns={'OdName':'Country', 'AreaName':'Continent','RegName':'Region'}, inplace=True)\n\n# for sake of consistency, let's also make all column labels of type string\ndf_can.columns = list(map(str, df_can.columns))\n\n# years that we will be using in this lesson - useful for plotting later on\nyears = list(map(str, range(1980, 2014)))\n\n# add total column\ndf_can['Total'] = df_can[years].sum(axis=1)\n\n#control dimensions\nprint ('data dimensions:', df_can.shape)\n```\n\nIn order to create a Choropleth map, we need a GeoJSON file that defines the areas/boundaries of the state, county, or country that we are interested in. In our case, since we are endeavoring to create a world map, we want a GeoJSON that defines the boundaries of all world countries. For your convenience, we will be providing you with this file, so let's go ahead and load it.\n\n```{python}\nimport io\nimport json\n\n# Opening JSON file\nf = open('../data/world_countries.json',)\nworld_geo = json.load(f)\nf.close()\n```\n\n```{python}\n# create a plain world map\nworld_map = folium.Map(location=[0, 0], zoom_start=2)\n```\n\nAnd now to create a `Choropleth` map, we will use the *choropleth* method with the following main parameters:\n\n1.  `geo_data`, which is the GeoJSON file.\n2.  `data`, which is the dataframe containing the data.\n3.  `columns`, which represents the columns in the dataframe that will be used to create the `Choropleth` map.\n4.  `key_on`, which is the key or variable in the GeoJSON file that contains the name of the variable of interest. To determine that, you will need to open the GeoJSON file using any text editor and note the name of the key or variable that contains the name of the countries, since the countries are our variable of interest. In this case, **name** is the key in the GeoJSON file that contains the name of the countries. Note that this key is case_sensitive, so you need to pass exactly as it exists in the GeoJSON file.\n\n```{python}\n# generate choropleth map using the total immigration of each country to Canada from 1980 to 2013\nworld_map.choropleth(\n    geo_data=world_geo,\n    data=df_can,\n    columns=['Country', 'Total'],\n    key_on='feature.properties.name',\n    fill_color='YlOrRd', \n    fill_opacity=0.7, \n    line_opacity=0.2,\n    legend_name='Immigration to Canada'\n)\n\n# display map\nworld_map\n```\n\n\nAs per our Choropleth map legend, the darker the color of a country and the closer the color to red, the higher the number of immigrants from that country. Accordingly, the highest immigration over the course of 33 years (from 1980 to 2013) was from China, India, and the Philippines, followed by Poland, Pakistan, and interestingly, the US.\n\nNotice how the legend is displaying a negative boundary or threshold. Let's fix that by defining our own thresholds and starting with 0 instead of -6,918\n\n\n```{python}\n# create a numpy array of length 6 and has linear spacing from the minimum total immigration to the maximum total immigration\nthreshold_scale = np.linspace(df_can['Total'].min(),\n                              df_can['Total'].max(),\n                              6, dtype=int)\nthreshold_scale = threshold_scale.tolist() # change the numpy array to a list\nthreshold_scale[-1] = threshold_scale[-1] + 1 # make sure that the last value of the list is greater than the maximum immigration\n\n# let Folium determine the scale.\nworld_map = folium.Map(location=[0, 0], zoom_start=2)\nworld_map.choropleth(\n    geo_data=world_geo,\n    data=df_can,\n    columns=['Country', 'Total'],\n    key_on='feature.properties.name',\n    threshold_scale=threshold_scale,\n    fill_color='YlOrRd', \n    fill_opacity=0.7, \n    line_opacity=0.2,\n    legend_name='Immigration to Canada',\n    reset=True\n)\nworld_map\n```"},"formats":{"html":{"execute":{"fig-width":3.5,"fig-height":3.5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":"auto","echo":true,"output":true,"warning":false,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"engine":"jupyter"},"render":{"keep-tex":false,"keep-yaml":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"wrap","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[]},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","output-file":"3_advanced_vis_tools.html"},"language":{},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.1.251","space-before-code-block":"10pt","space-after-code-block":"8pt","linespacing":"22pt plus2pt","frontmatter-linespacing":"17pt plus1pt minus1pt","title-size":"22pt","title-size-linespacing":"28pt","gap-before-crest":"25mm","gap-after-crest":"25mm","execute-dir":"file","theme":"cosmo"},"extensions":{"book":{"multiFile":true}}},"pdf":{"execute":{"fig-width":3.5,"fig-height":3.5,"fig-format":"pdf","fig-dpi":300,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":"auto","echo":true,"output":true,"warning":false,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"engine":"jupyter"},"render":{"keep-tex":false,"keep-yaml":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"pdf","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":true,"merge-includes":true,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[]},"pandoc":{"pdf-engine":"pdflatex","standalone":true,"variables":{"graphics":true,"tables":true},"default-image-extension":"pdf","to":"pdf","highlight-style":"github","output-file":"3_advanced_vis_tools.pdf"},"language":{},"metadata":{"block-headings":true,"space-before-code-block":"10pt","space-after-code-block":"8pt","linespacing":"22pt plus2pt","frontmatter-linespacing":"17pt plus1pt minus1pt","title-size":"22pt","title-size-linespacing":"28pt","gap-before-crest":"25mm","gap-after-crest":"25mm","execute-dir":"file","documentclass":"scrreprt","geometry":["heightrounded"],"pandoc_args":"--listings","header-includes":["\\usepackage{fvextra} \\DefineVerbatimEnvironment{Highlighting}{Verbatim}{breaklines,commandchars=\\\\\\{\\}}"],"colorlinks":true,"code-block-bg":"D3D3D3"},"extensions":{"book":{}}}}}